<html><head><title>Curriculum Vitae, LiuFang Guo</title><meta http-equiv="Content-Type" content="text/html; charset=utf-8" /><meta name="robots" content="nofollow" /><link rel="stylesheet" type="text/css" href="https://img00.zhaopin.cn/2012/css/reset.min.css" media="all" /><link rel="stylesheet" type="text/css" href="https://i.zhaopin.com/Content/css/resume_preview.css" media="all" /></head><body><div class="resumeBody"><div class="summary"><img width="70" height="90" align="right" class="headerImg" alt="Jerry" src="https://img00.zhaopin.cn/2012/img/my/v5/lookResumes.jpg" /><h1>LiuFang Guo</h1>Male<span class="ver-line">|</span>Unmarried<span class="ver-line">|</span>Age 30<span class="ver-line">|</span>
            UTC/GMT +8<span class="ver-line">|</span>
              Current Location: HaiDian District, BeiJing, China<br />Master of Science in Computer Technology
            <span class="ver-line">|</span>Bachelor of Science in Network Engineering<p>+86 18518755144</p><p>
              E-mail：<a href="mailto:909104374@qq.com">909104374@qq.com</a></p></div><dl class="details"><dt><h5>MINI-RESUME</h5></dt><dd><ul><li><strong>As student major in Computer Science for 7 years, good at Higher Mathematics include Limit, Calculus, Space Analytic Geometry, Linear Algebra and Probability Theory & Mathematical Statistics.</strong></li><li><strong>As internship in NavInfo classifing POIs.</strong></li><li><strong>As developer in TigerJoys doing Big Data R&D, data mining, initial machine learning.</strong></li><li><strong>And now as developer in Glodon Company Limited doing Big Data R&D, data mining, machine learning.</strong></li></ul></dd><dt><h5>SKILLS</h5></dt><dd><p style="width:574px; overflow:hidden;word-break: break-all; word-wrap:break-word;">
              1. familiar with the maintenance of CDH, HDP, Hadoop ecosystem related components, familiar with the solution of open source software problems<br/> 2. skilled use of R, Python, MATLAB analysis of data <br/>
3. familiar with the common data mining machine learning algorithm derivation and principles and applications <br/>
4. proficiency in Java, Scala, MR, spark application development <br/>
5. skilled use of talend ETL tools, Tableau data visualization tools. <br/>
6. proficiency in MAC Linux Git <br/>
7. good English reading, good mathematical foundation and quick learner <br/>
8. familiar with the basic steps and ideas of data analysis. <br/>
9. know about Caffe, tensorflow, Faster, Rcnn <br/></p></dd><dt><h5>EXPERIENCE</h5></dt><dd><div class="work-experience"><p>June 2017 -- Now
                          </p><h6>Glodon Company Limited<span class="ver-line">|</span>Big Data R&D, data mining, machine learning</h6><p><strong>DESCRIPTION:</strong><br />I am new here. Maintenance cluster, try to understand recommendation system, analyze product line data<br/></div><div class="work-experience"><p>June 2014 -- June 2017
                          </p><h6>Beijing TigerJoys Technology Co., Ltd.<span class="ver-line">|</span>Big Data R&D, data mining, machine learning</h6><p><strong>DESCRIPTION:</strong><br />The work experience is divided into two stages<br/>Stage A:  June 2014 -- November 2015<br/>Background:  I just graduated from graduate school. The company Data Department has just been established with two people plus me.<br/>Major contribution:<br/>1.After several iterations and upgrades, a stable data infrastructure platform  is established finally.This includes data collection (fluentd, flume), file storage (HDFS), log cleaning (MapReduce, Spark, Storm), warehousing (Hive, Hbase, Infinidb, GreenPlum). The storage and running environment of HA is constructed, and the real-time and off-line computing framework is constructed. We provide many data access interfaces (mysql, PSQL, Phoenix, web service, tableau, web report) to other departments.<br/>2.With the help of Talend and self defining job metadata, our ETL job is clear, tidy and fast. The creation and destruction of a ETL job can be controlled by several database records.<br/>3.The data warehouse is managed hierarchically, divided into three layers: (ODL, BDL, ADL).<br/>4.ClouderaManager is introduced to manage the cluster in a unified way。<br/>Stage B:  December 2015 -- April 2017<br/>Background: When the cluster is stable, I returned to my former career, data mining and machine learning.<br/>Major contribution:<br/>1.fake accesses analysis<br/>2.deliver classification system<br/></p><p><strong>Management Experience:</strong></p><p><span>
                                Reporting to: Chief Inspector</span><span><span class="ver-line">|</span>
                                  Group Member: 5</span></p><p><strong>Achievement Description: </strong>1.build a solid infrastructure data facilities;2.deliver classification system increases the root rate by 30%;3.improve team cohesion</p></div><div class="work-experience"><p>December 2013 -- June 2014</p><h6>9fbank(Internship)<span class="ver-line">|</span>Algorithm Engineer</h6><p><strong>DESCRIPTION:</strong><br />Major contribution:<br/>1.Recognition of Verification Code for specific sites<br/>&nbsp;&nbsp;&nbsp;&nbsp;The recognition process is basically divided into four steps, image preprocessing, segmentation, training and recognition. Because the verification code is very regular, the initial method is pixel matching. It has a high accuracy, but it is slow. Finally, I use libsvm with finding a balance point between speed and accuracy.<br/>2.Setup test environment of big data cluster<br/>&nbsp;&nbsp;&nbsp;&nbsp;Using the native Apache Hadoop, the HDFS storage and MR computing test environment was constructed.</p></div><div class="work-experience"><p>May 2013 -- October 2013</p><h6>NavInfo Co., Ltd.(Internship)<span class="ver-line">|</span>Information collection department- Algorithm Engineer</h6><p><strong>DESCRIPTION:</strong><br />Major contribution:<br/>1.Solve IP Forbidden of Crawler<br/>&nbsp;&nbsp;&nbsp;&nbsp;send HTTP requests to TP-Link router, so can control online or offline.
At every time the modem offline then online, China Unicom will allocate a new IP to Crawler Machine from the huge pool of IP. <br/>2.Text Classification<br/>&nbsp;&nbsp;&nbsp;&nbsp;Split chinese vocabulary; construct document vector by using custom dictionary; the dimention value is the TF-IDF of the vocabulary; complete the rough classification by using Bayes classifier. Delivery the result to Road, Bus group for further processing.</p></div></dd><dt><h5>HOBBIES AND INTERESTS</h5></dt><dd><p>Basketball, badminton with poor skill which teammates can only tolerate me</p></dd></dl><input id="neturlparam" type="hidden" value="AppId=1&Id=616125497&Timestamp=1500781081&Callback=&signature=D66EBD4DA69C4EF5C46A384799ECFB60" /></div></body></html>